{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "460d4df11b984ca9a1c85a88a6782423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f33f64b25a374077808b7896527b68c6",
            "placeholder": "Enter your prompt here...",
            "rows": null,
            "style": "IPY_MODEL_336603684f5d4183b452e84d287106b0",
            "value": ""
          }
        },
        "f33f64b25a374077808b7896527b68c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "336603684f5d4183b452e84d287106b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f90bc3cf2660446294754349494b7505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Get Groq Response",
            "disabled": false,
            "icon": "play",
            "layout": "IPY_MODEL_7d6444e5d27848cdadde8be5f8e5e9ae",
            "style": "IPY_MODEL_d5e120ea2ecc4209a83dfd12ccd2e805",
            "tooltip": "Click to get response from Groq"
          }
        },
        "7d6444e5d27848cdadde8be5f8e5e9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e120ea2ecc4209a83dfd12ccd2e805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "bf85ce6714df46afa0c3c73e9fd467ce": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0d10bba9b5144c9b8e3852e44d08867a",
            "msg_id": "",
            "outputs": []
          }
        },
        "0d10bba9b5144c9b8e3852e44d08867a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8luyrwlVa_Pa",
        "outputId": "3b9945a9-833d-4f36-a13a-77fe15d52e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=\"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\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  store=True,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dNQtBbxcEuR",
        "outputId": "40e79137-da5b-4032-eb0d-6136a8e85036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Silent thoughts in code,  \\nDreams of logic intertwine,  \\nMachines learn to feel.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k12telaVd7Gb",
        "outputId": "d8b69ad3-411d-406b-9aa6-76332ddc65f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.29.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.29.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY = userdata.get('Demo3')"
      ],
      "metadata": {
        "id": "JAE-sk1Zob2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "\n",
        "client = Groq(\n",
        "\n",
        "    api_key=(GROQ_API_KEY),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A7cw8AgcFNi",
        "outputId": "3a2d5525-470e-4b2e-a14a-c36fa99cd17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models have become crucial in the field of natural language processing (NLP) due to their ability to process and generate human-like language at an unprecedented speed. The importance of fast language models can be seen in the following aspects:\n",
            "\n",
            "1. **Improved User Experience**: Fast language models enable applications to respond quickly to user input, creating a seamless and interactive experience. This is particularly important in applications such as chatbots, virtual assistants, and language translation software.\n",
            "2. **Real-time Processing**: Fast language models can process and analyze large amounts of data in real-time, allowing for applications such as:\n",
            "\t* Sentiment analysis: quickly analyzing user feedback and sentiment.\n",
            "\t* Text classification: rapidly categorizing text into predefined categories.\n",
            "\t* Named entity recognition: swiftly identifying and extracting specific entities from text.\n",
            "3. **Efficient Content Generation**: Fast language models can generate high-quality content, such as:\n",
            "\t* Automated writing: quickly producing articles, blogs, and other written content.\n",
            "\t* Summarization: rapidly summarizing long documents or articles.\n",
            "\t* Language translation: quickly translating text from one language to another.\n",
            "4. **Enhanced Decision-Making**: Fast language models can provide insights and analytics in real-time, enabling businesses and organizations to make informed decisions quickly. This is particularly useful in applications such as:\n",
            "\t* Social media monitoring: rapidly analyzing social media trends and sentiment.\n",
            "\t* Customer service: quickly responding to customer inquiries and resolving issues.\n",
            "5. **Scalability and Cost-Effectiveness**: Fast language models can handle large volumes of data and user requests without significant increases in computational resources or costs. This makes them ideal for applications that require high scalability and performance.\n",
            "6. **Advancements in NLP Research**: Fast language models have accelerated research in NLP, enabling scientists to explore new ideas and applications more quickly. This has led to breakthroughs in areas such as:\n",
            "\t* Language understanding: improving the ability of models to comprehend human language.\n",
            "\t* Language generation: developing models that can generate coherent and contextually relevant text.\n",
            "7. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by:\n",
            "\t* Improving customer engagement and satisfaction.\n",
            "\t* Enhancing operational efficiency and productivity.\n",
            "\t* Developing innovative products and services.\n",
            "\n",
            "In summary, fast language models have become essential in the field of NLP due to their ability to process and generate high-quality language quickly, efficiently, and at scale. Their importance extends to various applications, including user experience, real-time processing, content generation, decision-making, scalability, and research advancements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=(GROQ_API_KEY),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is an API\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP4efshnd5SZ",
        "outputId": "e9aaeaef-6fb3-4128-9fbe-7d363fe888c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**API Overview**\n",
            "===============\n",
            "\n",
            "An **Application Programming Interface (API)** is a set of defined rules that enables different applications, systems, or services to communicate with each other. It allows them to exchange data, perform actions, or request services in a standardized and structured way.\n",
            "\n",
            "**Key Characteristics**\n",
            "--------------------\n",
            "\n",
            "1. **Interface**: An API serves as an interface between two or more systems, allowing them to interact with each other.\n",
            "2. **Standardized**: APIs follow established standards, protocols, and formats to ensure compatibility and interoperability.\n",
            "3. **Programmable**: APIs are designed to be used by software applications, allowing developers to integrate them into their own code.\n",
            "4. **Data exchange**: APIs facilitate the exchange of data, including requests, responses, and notifications.\n",
            "\n",
            "**How APIs Work**\n",
            "----------------\n",
            "\n",
            "1. **Request**: A client application (e.g., a web app, mobile app, or server) sends a request to an API endpoint.\n",
            "2. **API endpoint**: The API endpoint receives the request and processes it.\n",
            "3. **Response**: The API endpoint returns a response to the client application, which may include data, an error message, or a confirmation of the action performed.\n",
            "\n",
            "**Types of APIs**\n",
            "-----------------\n",
            "\n",
            "1. **Web API**: Exposes functionality over the web, using protocols like HTTP, HTTPS, or WebSocket.\n",
            "2. **Library API**: A collection of reusable code that provides a set of functionalities, often used within a single application or system.\n",
            "3. **Operating System API**: An interface between an operating system and applications, allowing them to interact with the OS.\n",
            "\n",
            "**Benefits of APIs**\n",
            "-------------------\n",
            "\n",
            "1. **Integration**: APIs enable seamless integration between different systems, services, or applications.\n",
            "2. **Reusability**: APIs promote code reusability, reducing development time and costs.\n",
            "3. **Flexibility**: APIs allow developers to access functionality from multiple platforms, devices, and languages.\n",
            "4. **Scalability**: APIs enable systems to scale more efficiently, as they can handle a large volume of requests and data exchanges.\n",
            "\n",
            "**Real-World Examples**\n",
            "----------------------\n",
            "\n",
            "1. **Social media**: APIs are used to share content, authenticate users, or retrieve data from social media platforms.\n",
            "2. **Payment gateways**: APIs facilitate online transactions, enabling merchants to integrate payment processing into their applications.\n",
            "3. **Mapping services**: APIs provide location data, allowing developers to embed maps, geolocation, and routing functionality into their applications.\n",
            "\n",
            "In summary, an API is a standardized interface that enables different systems, applications, or services to communicate with each other, exchange data, and perform actions in a structured and programmable way.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FAVWfxzunEr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "ec54b44a",
        "outputId": "8c28fedf-de63-4022-fc46-16d117eae33e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'chat_completion' is the response object from your Groq API call\n",
        "# If your server response is in a different format (like a dictionary or JSON string),\n",
        "# you might need to adjust how you access the data.\n",
        "\n",
        "# For the Groq API response, the content is in chat_completion.choices[0].message.content\n",
        "response_data = {\n",
        "    \"Role\": chat_completion.choices[0].message.role,\n",
        "    \"Content\": chat_completion.choices[0].message.content,\n",
        "    \"Model\": chat_completion.model,\n",
        "    # You can add other relevant information from the response here\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# We create a DataFrame from a list containing one dictionary to ensure columns\n",
        "df = pd.DataFrame([response_data])\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Role                                            Content  \\\n",
              "0  assistant  Fast language models have become crucial in th...   \n",
              "\n",
              "                     Model  \n",
              "0  llama-3.3-70b-versatile  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88ea4334-c588-40dc-8280-516c09e9cdae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Role</th>\n",
              "      <th>Content</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>assistant</td>\n",
              "      <td>Fast language models have become crucial in th...</td>\n",
              "      <td>llama-3.3-70b-versatile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88ea4334-c588-40dc-8280-516c09e9cdae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88ea4334-c588-40dc-8280-516c09e9cdae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88ea4334-c588-40dc-8280-516c09e9cdae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_ee170366-e3fd-4924-84ba-91baf86c4eac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ee170366-e3fd-4924-84ba-91baf86c4eac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Role\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"assistant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Fast language models have become crucial in the field of natural language processing (NLP) due to their ability to process and generate human-like language at an unprecedented speed. The importance of fast language models can be seen in the following aspects:\\n\\n1. **Improved User Experience**: Fast language models enable applications to respond quickly to user input, creating a seamless and interactive experience. This is particularly important in applications such as chatbots, virtual assistants, and language translation software.\\n2. **Real-time Processing**: Fast language models can process and analyze large amounts of data in real-time, allowing for applications such as:\\n\\t* Sentiment analysis: quickly analyzing user feedback and sentiment.\\n\\t* Text classification: rapidly categorizing text into predefined categories.\\n\\t* Named entity recognition: swiftly identifying and extracting specific entities from text.\\n3. **Efficient Content Generation**: Fast language models can generate high-quality content, such as:\\n\\t* Automated writing: quickly producing articles, blogs, and other written content.\\n\\t* Summarization: rapidly summarizing long documents or articles.\\n\\t* Language translation: quickly translating text from one language to another.\\n4. **Enhanced Decision-Making**: Fast language models can provide insights and analytics in real-time, enabling businesses and organizations to make informed decisions quickly. This is particularly useful in applications such as:\\n\\t* Social media monitoring: rapidly analyzing social media trends and sentiment.\\n\\t* Customer service: quickly responding to customer inquiries and resolving issues.\\n5. **Scalability and Cost-Effectiveness**: Fast language models can handle large volumes of data and user requests without significant increases in computational resources or costs. This makes them ideal for applications that require high scalability and performance.\\n6. **Advancements in NLP Research**: Fast language models have accelerated research in NLP, enabling scientists to explore new ideas and applications more quickly. This has led to breakthroughs in areas such as:\\n\\t* Language understanding: improving the ability of models to comprehend human language.\\n\\t* Language generation: developing models that can generate coherent and contextually relevant text.\\n7. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive advantage by:\\n\\t* Improving customer engagement and satisfaction.\\n\\t* Enhancing operational efficiency and productivity.\\n\\t* Developing innovative products and services.\\n\\nIn summary, fast language models have become essential in the field of NLP due to their ability to process and generate high-quality language quickly, efficiently, and at scale. Their importance extends to various applications, including user experience, real-time processing, content generation, decision-making, scalability, and research advancements.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"llama-3.3-70b-versatile\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rk97NV3wpyXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "625cf787"
      },
      "source": [
        "# Install ipywidgets if you haven't already\n",
        "# !pip install ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "460d4df11b984ca9a1c85a88a6782423",
            "f33f64b25a374077808b7896527b68c6",
            "336603684f5d4183b452e84d287106b0",
            "f90bc3cf2660446294754349494b7505",
            "7d6444e5d27848cdadde8be5f8e5e9ae",
            "d5e120ea2ecc4209a83dfd12ccd2e805",
            "bf85ce6714df46afa0c3c73e9fd467ce",
            "0d10bba9b5144c9b8e3852e44d08867a"
          ]
        },
        "id": "9b57dd8b",
        "outputId": "3a113a13-0518-4fc7-e07f-3aff50d49221"
      },
      "source": [
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "# Assuming GROQ_API_KEY is already defined from your user data secrets\n",
        "# from google.colab import userdata\n",
        "# GROQ_API_KEY = userdata.get('YourGroqAPIKeyName') # Replace 'YourGroqAPIKeyName' with your secret name\n",
        "\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "# Create widgets\n",
        "prompt_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Enter your prompt here...',\n",
        "    description='Prompt:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='80%', height='100px')\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(\n",
        "    description='Get Groq Response',\n",
        "    disabled=False,\n",
        "    button_style='primary', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click to get response from Groq',\n",
        "    icon='play'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# Function to call Groq API and display response\n",
        "def on_submit_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output() # Clear previous output\n",
        "        if prompt_input.value:\n",
        "            print(\"Getting response...\")\n",
        "            try:\n",
        "                chat_completion = client.chat.completions.create(\n",
        "                    messages=[\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": prompt_input.value,\n",
        "                        }\n",
        "                    ],\n",
        "                    model=\"llama-3.3-70b-versatile\", # You can change the model here\n",
        "                )\n",
        "                print(\"Groq Response:\")\n",
        "                print(chat_completion.choices[0].message.content)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "        else:\n",
        "            print(\"Please enter a prompt.\")\n",
        "\n",
        "# Link button click to the function\n",
        "submit_button.on_click(on_submit_button_clicked)\n",
        "\n",
        "# Display the widgets\n",
        "display(prompt_input, submit_button, output_area)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Prompt:', layout=Layout(height='100px', width='80%'), placeholder='Enter your …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "460d4df11b984ca9a1c85a88a6782423"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='primary', description='Get Groq Response', icon='play', style=ButtonStyle(), tooltip='Cli…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f90bc3cf2660446294754349494b7505"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf85ce6714df46afa0c3c73e9fd467ce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGTUKqhtr8z9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}